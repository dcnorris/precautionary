TODO
====

NEW & IMPROVED PLAN

So, the plan below evaporated quickly after a half-day of thinking
in my notebook! A new, more focused plan has emerged as follows:

/1) Initial target is a cross-tabulation by r0 and ordinal Tox,
    displaying counts of enrolled patients over all reps within
    each given draw from (sigma(CV), mu) and the 'true_prob_tox'
    vector that yields.
    
/2) That crosstab can then be normalized to expected numbers of
    each toxicity grade in the trial. (The sum of these of course
    yields the expected enrollment in the trial.)
    
(3) REFACTOR package 'escalation' in the direction of abstractions
    pointed to by 'precautionary'.
    ** The aim here is to better appreciate at once these new
       generative models and the escalation::simulate_trials function
       that I wish to 'correct while explaining' in accordance with
       Popper's notion of the 'depth of a theory'.
    
 a. The question arises, to what extent *generative models* may be
    substituted in place of fixed 'true_prob_tox' vectors within
    the existing 'escalation' code-base. What changes would this
    require?
    
    It looks to me as if my S4 generic 'simulate_trials' method
    could simply be expanded to accept a new signature where the
    3rd argument is an 'MTDi_generator' or 'toxicity_generator'.
    
    Importantly, this would enable me to offer up (and refine!) an
    abstract formulation of this generative-model concept.
    
    Probably, the mtdi_generator and ordtox_generator are distinct
    concepts requiring separate classes. (Perhaps the latter emerges
    as a subclass of the former!)
    
 b. Notice that the task of *specifying* these generative models
    naturally gives rise to questions of scaling and dimensioning.
    Thus, I may have here the needed (and inevitable) stimulus to
    thinking about explicity (dimensioned) dosing.
    
(4) REFACTORING this code, by contrast, seems essential to MY OWN
    understanding of what I've done!
    
/a. Implement my own 'simulate_trials' generic function, dispatching on a
    special class 'ordtox' that I can prepend to a selector_factory object
    in a call such as the following:
    
    > simulate_trials(check_safety(sims), num_sims = __, priors = __)
    
    where the wrapper 'check_safety' prepends the class.
    
    This allows me to leave escalation::simulate_trials as the default,
    but to implement my own function. Ideally, I would like to guide
    users of package 'escalation' toward checking safety, with minimal
    changes to their own code. Thus, I really should support the basic
    syntax with num_sims and true_prob_tox arguments, possibly ignoring
    or going beyond these.
    by package 'escalation'. When invoked with a 'true_prob_tox' argument,
    this can simply revert to invoking escalation::simulate_trials.
    But when invoked *without* this specified, it draws the probabilities
    from a prior specified in '...' initially. (Eventually, I may consider
    implementing this in a package-specific option.)
    
    Given the design intent reflected in the simulation_function.* methods,
    I wonder whether it would increase clarity and abstraction for me to
    'inject' a class such as 'check_safety' into the class list BEFORE
    the 'tox_selector_factory' class. This might allow me to return my own
    customized version of phase1_sim instead of having to do a pull request.
    
    Hmm.. What happens in R if a generic function shadows a plain old function?
    What would happen if I rewrote 'simulate_trials' as an S3 method? Would
    dispatch occur?
    
    AHA! This seems to be EXACTLY the scenario where setGeneric() applies.
    There is an existing function simulate_trials in another package, and
    I want to define additional methods for that function.
    
    simulate_trials <- function(selector_factory, num_sims, true_prob_tox, ...) {
      sim_func <- simulation_function(selector_factory)
      l <- lapply(
        1:num_sims,
        function(x) sim_func(selector_factory, true_prob_tox, ...)
      )
  simulations(fits = l, true_prob_tox = true_prob_tox)
}

    
    Absent a close collaboration with the author of package 'escalation',
    I am probably stuck with syntax like that above, which would enable
    me to impose a change of signature. Retaining the original signature,
    but with the 'true_prob_tox' argument generalized to accept priors
    (over *ordinal* toxicities!) would require a coherent redesign of the
    escalation package: ordinal toxicities would have to be handled in
    a coherent way, for example.
    
 b. Note that the 'priors' above might best be obtained from options
    specific to my package. The right-minded approach to designing the
    trial (also, the truly *Bayesian* approach, FWIW) demands setting
    out such priors in advance. Setting package options nicely aligns
    with that modus operandi, and with a regard for these priors as
    honestly posited, and as stable for the duration of a trial-design
    session.
    
 c. The 'check_safety' class implicit in the above syntax affords an
    opportunity to implement the summary statistics through 'print'
    methods that generalize 'simulations.print'.
    
    Or maybe the check_safety *wrapper* merely appends a 'precautionary'
    class to the selector_factory in the 1st argument, strictly for
    method-dispatch purposes. The 'simulations' object returned might
    then more appropriately get an 'ordinaltox' or 'CTCAE' class appended
    to it, and the existing 'tox' column then gets overwritten with what
    I currently denote (capital-T) 'Tox'.
    
 d. These refactoring considerations point to the status of parameters
    such as r0 as a separate concern that may more properly be handled
    within the existing 'escalation' package.
    
    Pending the development of any closer collaboration with escalation's
    author, I will do best to extend the 'simulations' class within my
    own package. Certainly, the existing 'simulations' class exposes what
    may be a highly appropriate interface, which I should consider adhering
    to as much as possible. A suitable name for the new class might be
    'factorial_simulations', say.
    
    Indeed, even upon a cursory glance I stumble upon simulations method
    'dose_indices', which can improve my implementation of sim_safety and
    also be implemented (or inherited!) by a factorial_simulations class!
    
 e. Further refactoring opportunities may ultimately come into focus
    through this effort. For example, is there a generic class of ordinal
    toxicity generators, capable of subsuming the PO and CR models of
    Van Meter &al (2011,2012), as well as my own model? What will such
    a class reveal about the former by comparison with the latter?
    
    I now think that this issue of generative models constitutes the next
    best point of improvement. Notice how even the existing 'escalation'
    package might naturally admit generative models in place of fixed
    'true_prob_tox' vectors. This seems important enough to bubble upward
    to the top level as TODO #3 above...

(5) VISUALIZING this process seems essential for communicating
    the basic idea to oncology trialists. One such viz that comes
    to mind is a representative set of 20 or so 'true_prob_tox'
    curves (NB: these should be smoothed) that support roll-over
    interaction with a sub-table (inset?) display.

---

A key consideration as I begin, is how (and whether) to deal with
absolute vs ordinal doses. One possibility is to suppose that any
ordinal (1, 2, 3, ...) doses are scaled either logarithmically or
arithmetically (perhaps set by a package option), with a generic
case handled by a monotone function.

In case an optional vector of dimensioned doses is provided, then
the package should adapt printed displays to include these alongside
any dose level. (Also, concreteness being a cognitive convenience
for users, these absolute doses might also serve as references for
specification of MTDi distribution centrality. But such 'speculative
generality' might best be left as a later refinement.)

1. Implement MTDi.distribution package options(mu, CV, r0),
   defaulting to generally plausible values,
   
2. Redo the vignette by reference to these options

3. Investigate 'hiding' the extra work by shadowing method.
   This is an interesting possibility, which may even challenge
   usual notions of 'good programming practice' in R or on CRAN.
   