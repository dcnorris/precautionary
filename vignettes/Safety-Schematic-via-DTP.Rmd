---
title: "Universal dose-escalation safety schematics via Dose Transition Pathways (DTP)"
author: "David C. Norris"
date: "12/26/2020"
output:
  bookdown::tufte_html2:
    highlight: pygments
vignette: <
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Universal safety schematics via DTP}
  \usepackage[utf8]{inputenc}
bibliography:
  - precautionary-package.bib
  - packages.bib
header-includes:
  \newcommand{\MTDi}{\mathrm{MTD}_i}
  \newcommand{\MTDig}[1][g]{\mathrm{MTD}_i^{#1}}
  \newcommand{\CV}{\mathrm{CV}}

---

```{r setup, include=FALSE}
old <- options(rmarkdown.html_vignette.check_title = FALSE) # suppress un-needed warning
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.height = 4, fig.width = 6)

library(precautionary)
library(knitr)
library(kableExtra)
library(dplyr)
library(dtpcrm)

options(ordinalizer = NULL) # vignette presumes this is not already set

# Echo source focused on package functionality by redacting calls to kable()
# see https://bookdown.org/yihui/rmarkdown-cookbook/hook-hide.html:
local({
  hook_source <- knitr::knit_hooks$get('source')
  knitr::knit_hooks$set(source = function(x, options) {
    x <- gsub(" -> etc.", "", x)
    x <- x[!grepl("^etc. %>%", x)] # strip lines starting "etc. %>% ..."
    x <- x[!grepl("\\(etc.,", x)]  # strip lines with fun(etc., ...)
    hook_source(x, options)
  })
})
```

# Aims

@norris_what_2020 proposed a universal schematic for evaluating the safety of the 3+3 dose-escalation design, and conjectured that the *dose transition pathways* (DTP) of @yap_dose_2017 would enable a similar treatment of model-based designs. This vignette explores that conjecture in relation to the continual reassessment method (CRM), through the `dtpcrm` package [@R-dtpcrm].

# Generalized exact simulation of dose escalation

Dose-escalation trial designs commonly operate with a fixed set of $D$ prespecified doses, enrolling small cohorts of $n$ participants at doses selected sequentially according to observed counts of binary dose-limiting toxicities (DLTs). Under such designs, the observations at any point in the trial may be recorded in a $C \times D$ matrix of toxicity counts $\{0, 1, ..., n, -\}$, with $-$ being used where a cohort has not been enrolled. Indeed, for deterministic designs in which dose-escalation decisions depend strictly on the history of observed DLT counts, such matrices suffice to account for the full dose-escalation sequence.^[To see this, consider that one may 'read' such a matrix, starting from the (deterministic) starting dose, and applying the (deterministic) design rules at each step. That is, a deterministic design *by definition* imposes a unique sequence on the entries in such a matrix.] For designs with upper bounds on enrollment, $C$ may be fixed *ex ante*, and all possible paths comprehensively enumerated.

In @norris_what_2020, for example, paths through the 3+3 design could be represented as $2 \times D$ matrices because the 3+3 design enrolls at most 2 cohorts at any given dose. The mathematical treatment offered there for the path matrices $T_{c,d}^j$ was independent of the 3+3 rules, however, and carries forward generally:

Denoting the prespecified doses by $(X_d)$ and the cumulative distribution function of $\MTDi$ by $P$, we can write the vector $(\pi^j)$ of path probabilities:^[Products or sums over $c$ or pairs $(c,d)$ are understood to be taken over the *non-empty* cohorts thus indexed. In R, this convention is applied by representing $-$ with `NA`, and using option `na.rm=TRUE` in aggregate operations.]

$$
\begin{align}
p_d &= P(\MTDi < X_d)\quad\mbox{(dose-wise toxicity probabilities)}\\
q_d &= 1 - p_d\\
\pi^j &= \prod_{c,d} {n \choose T_{c,d}^j} p_d^{T_{c,d}^j} q_d^{(n-T_{c,d}^j)}\quad\mbox{(path probabilities)} (\#eq:pi)
\end{align}
$$

Again as in @norris_what_2020, taking logs in \@ref(eq:pi) we find:

$$
\log \boldsymbol{\pi} = \sum_{c,d} \log {n \choose T_{c,d}} + \sum_c [T_{c,d},n-T_{c,d}]\left[{ \log \mathbf{p} \atop \log \mathbf{q}} \right] = \mathbf{b} + U\left[{ \log \mathbf{p} \atop \log \mathbf{q}} \right], (\#eq:logpi)
$$
where the $J \times 2D$ matrix $U$ and the $J$-vector $\mathbf{b}$ are characteristic *constants* of the dose-escalation design.^[In @norris_what_2020, which considered the very narrow space of 3+3 designs, $\mathbf{b}$ and $U$ could be indexed with $D$ subscripts. As we are now considering a much larger space of designs, we here omit those subscripts. This is in accordance with our view that feasible comprehensive safety analysis of complex dose-finding designs must generally proceed from specifications that enable automatic, dynamic code generation.]

Finally, we may as previously introduce the log-therapeutic index $\kappa$, enabling us to write the fatal (grade-5) fraction $f_d$ of DLTs as:

$$
f_d = \frac{P(e^{2\kappa} \MTDi <  X_d)}{P(\MTDi < X_d)}, (\#eq:fatalfraction)
$$

in terms of which the expected number of fatal toxicities is:

$$
\boldsymbol{\pi}^\intercal \mathrm{Y} \mathbf{f},  (\#eq:fatalities)
$$

where $Y = \sum_c T_{c,d}^j$ denotes the $(J \times D)$ left half of $U$.

# Connection with DTP

TODO: Characterize DTP, and note its relationship to my own enumerative undertaking. Does DTP anticipate such complete enumeration, with its possibilities for exact simulation?

# An application

We will adopt the same parameters as in the `dtpcrm` [package vignette](https://cran.r-project.org/web/packages/dtpcrm/vignettes/dtpcrm_vignettev02.html):

## VIOLA set-up

### Clinical parameters

```{r clinical-params}
number.doses <- 7
start.dose.level <- 3
max.sample.size <- 21
target.DLT <- 0.2
cohort.size <- 3
```

Note that the sample size limit allows us to set $C=7$.

### Model specification parameters

```{r model-spec-params}
prior.DLT <- c(0.03, 0.07, 0.12, 0.20, 0.30, 0.40, 0.52)
prior.var <- 0.75
```

### Practical considerations

```{r practicalities}
no_skip_esc <- TRUE
no_skip_deesc <- FALSE
global_coherent_esc <- TRUE
```

### Early stopping

```{r early-stopping}
stop_func <- function(x) {
  y <- stop_for_excess_toxicity_empiric(x,
                                        tox_lim = target.DLT + 0.1,
                                        prob_cert = 0.72,
                                        dose = 1,
                                        nsamps = 100000)
  if(y$stop){
    x <- y
  } else {
    x <- stop_for_consensus_reached(x, req_at_mtd = 12)
  }
}
```

## Computing DTPs

```{r compute-dtp, eval=FALSE}
t0 <- proc.time()
viola_dtp <- calculate_dtps(next_dose = start.dose.level,
                            cohort_sizes = rep(cohort.size, 7),
                            dose_func = applied_crm,
                            prior = prior.DLT,
                            target = target.DLT,
                            stop_func = stop_func,
                            scale = sqrt(prior.var),
                            no_skip_esc = no_skip_esc,
                            no_skip_deesc = no_skip_deesc,
                            global_coherent_esc = global_coherent_esc
                            )
saveRDS(viola_dtp, file="viola_dtp.rds")
proc.time() - t0 # NB: For C=7, this took just under 17 minutes to compute
```

```{r load-cached-dtp, echo=FALSE}
# Read cached viola_dtp from disk
viola_dtp <- readRDS("../viola_dtp.rds")
```

Each of (up to) 7 cohorts enrolled having 4 possible outcomes (0, 1, 2 or 3 toxicities), the DTP calculation lists a total of $4^7 = 16384$ distinct paths. Due to early stopping, however, some of these paths will be degenerate. For example, we can see that paths 1005--1008 all terminate at the 6th cohort resulting in a $4\times$ degeneracy:
```{r degenerates}
knitr::kable(viola_dtp[1000:1010,])
```

The degree of degeneracy is indeed quite substantial:
```{r degeneracy}
viola_paths <- unique(viola_dtp)
nrow(viola_paths)
```

# Computing $\mathbf{b}$ and $U$ from the DTP table

The number of possible paths $J_D$ for a standard 3+3 design grows almost exponentially with the number of dose levels $D$, as shown in Table \@ref(tab:JvD).

```{r JvD, echo=FALSE}
JvD <- data.frame(
  D = 1:10
, J = c(10, 46, 154, 442, 1162, 2890, 6922, 16138, 36874, 82954) # TODO: Obtain from package data
)
JvD$`log(J)` <- log(JvD$J)
JvD$`∆ log(J)` <- c(NA, diff(JvD$`log(J)`))
knitr::kable(JvD, caption = "Number of possible dose-escalation paths in the standard 3+3 design, as a function of the number $D$ of prespecified doses.", digits = 2) %>%
  kable_styling(full_width = FALSE)
```

Thus, for values of $D \le 7$ typical in 3+3 designs, the $2 \times D \times J$ arrays $(T_{c,d}^j)$ needed to fully represent trial events are quite manageable in size and permit a simple expression of path probabilities.


## Issues of degeneracy

Some degeneracy is created by multiple paths that have equivalent toxicity counts per dose level. All that matters for this calculation is the net probability of all paths leading to given counts per toxicity level. Note that the individual-path probabilities must be calculated before aggregation, but that this aggregation may occur before the mapping to counts of graded toxicities.

**TODO:** Assess the amount and importance of the degeneracy that can be exploited. Does this allow me to cut the size of stored matrices in half, or better?

```{r A-degeneracy}
degen <- data.frame(D = 2:7)
degen$Unique_paths <- sapply(degen$D, function(D)
  dim(precautionary:::T[[D]])[3])
degen$Unique_toxcounts <- sapply(degen$D, function(D) {
  # Obtain (D*J) matrix T of dose-wise toxcounts
  T <- apply(precautionary:::T[[D]]
             , MARGIN = 2:3 # sum on 1st dim (cohorts 1:2)
             , FUN = sum, na.rm = TRUE) # regard NA = 0
  ncol(unique(T, MARGIN = 2)) # count unique D-toxcounts
})
degen$Inflation <- with(degen, Unique_paths / Unique_toxcounts)
knitr::kable(degen, caption = "Degeneracy of dose-escalation paths, relative to dose-wise toxicity counts, for the standard 3+3 design with 2--7 prespecified doses.", digits = 2) %>%
  kable_styling(full_width = FALSE)
```

In what follows, we override the default 3+3 design of package `escalation`, to use what @korn_comparison_1994 called the "more common" of two "variants of the standard method." This also aligns with the 3+3 method as defined in @skolnik_shortening_2008 [p191; emphasis is mine]:

> "The MTD is defined as the dose level at which none or one of six participants (0% to 17%)
> experience a DLT, *when at least two of three to six participants (33% to 67%) experience
> a DLT at the next highest dose.*"


# Toxicity contours in the $(\mathrm{CV}, r_0)$-plane

I hope that, for a given $D$, and a geometric sequence of doses with a given ratio $\rho$, there will be one characteristic surface of expected number of fatalities over the $(\mathrm{CV}, r_0)$-plane. Thus, my aim will be to produce a small array of contour plots that fully account for the implicit priors. A basic hope is that $\rho$ will 'factor out' of these plots, perhaps because $r_0/\rho$ appears on one axis.

The essential approach, then, is to calculate a relatively dense array of points in this plane, to support the drawing of contours. I am prepared for the possibility that this has to be done outside of R, perhaps even by a Mercury program. But at least some initial indications of the structure of these contour plots should be obtainable as a `levelplot` on a coarse grid.

Whereas $r_0/\rho$ does indeed seem to be an invariant, the same cannot be said for transformations of CV. One barrier to finding invariant axes for this plot may well be the overlaid integration against a prior. Accordingly, let me aim instead to *postpone* any such integration until the plot has been drawn.

This postponement allows the problem of dimensionality to resurface, however. A great benefit of the early integration was the dimension reduction it accomplished by integrating out the `median_mtd` parameter. If I want a diagram on which the points correspond to a strictly simulated 'known truth', then I seem to be stuck with both parameters of the lognormal MTDi distribution. This, in turn, means that quantities like $r_0$ (and perhaps other parameters of the hyperprior?) no longer appear on the axes of a single, simple plot. Perhaps I end up with an array of plots (indexed by $D$ and $r_0/\rho$, say) that you could use for any given design.

But note that there is a great deal of value in the *concreteness* of points in the plane corresponding to unknown pharmacological states-of-the-world. At the *concluding* level of this paper, I do expect to require a plot where the points represent priors. But in the **development** toward that conclusion, I will need explanatory (and *exploratory*!) figures where the points represent more concrete, objective realities.

The most flexible approach to this initial exploration may be to build a high-dimensional *array* that I can freely slice, aggregate, etc. What are its dimensions?

* $D$ ranging over 3--8 doses, say
* $\rho$ ranging 1.4--3
* $r_0$ some range of values (hope to collapse with above!)
* `meanlog` $\MTDi$ ranging from lowest to highest dose?
* `sdlog` of $\MTDi$

**Crucially, for every invariance (dimensionless constant of the field) I manage to demonstrate, I can freely eliminate one of these dimensions.**

Fixing $D$ initially, and *anticipating* that safety will prove to be a function of $r_0/\rho$, I can operate initially with 3 dimensions in the array.

```{r contourplot, echo=FALSE, fig.asp=1, fig.fullwidth=TRUE, fig.cap="Contours of expected fatalities per trial."}
b <- precautionary:::b
U <- precautionary:::U
D <- 4
# Build a 3-dimensional array log(r0)/log(rho) x (MDT50) x (SDLOG/log(rho)),
# where the median MTDi doses 'MTD50' are indexed to the (integer) dose levels.
# The design decisions (i.e., post-hoc prior elicitation) then refer questions
# about r0 to log(r0)/log(rho).
# For example, if rho=2 and r0=sqrt(2), then each dose level goes up by r0^2
# from the previous one. Conversely, if r0=4, then each dose level goes up by
# a factor of sqrt(r0) from the previous.
# Q: Do *decibels* help us to express these concepts better?
# 1 dB => 1.26 power ratio
# 2 dB => 1.58
# 3 dB => 2.00
# 6 dB => 3.98
# But does the dB help me discuss the *ratio* of two logarithms?
# Am I not really looking for log_{rho}(r0)? YES! But, ... maybe it looks nicer
# to understand that rho & r0 are themselves given in logarithmic units, so that
# I may then write "r0/rho" instead of "log(r0)/log(rho)" or (worse!) "log_rho(r0)".
# It also does seem advantageous to me, that we thus introduce an 'engineering spirit'
# into the discourse.
# Might a concept like *gain* of an amplifier help here? I think not, because
# the signals' power ratio is being compared.
# Define a range of r0 & rho values logarithmically, so that r0/rho is constant
# along all diagonals of the matrix outer(r0, rho, FUN = `/`). This will enable
# easy visual checks of invariance to this dimensionless quantity.
## Hmm ...
# I think the symmetry is captured by log(r0)/log(rho), rather than by r0/rho.
# This concept is important enough that I feel justified introducing new notation
# to express it. Let me call it ∆, and let it be measured *logarithmically* in
# dose-interval units. I may need to introduce some conventions, by which (say)
# capital Greek letters are measured in dB. Alternatively, we might set ∆ as the
# (logarithmic) dose interval (WLOG measured in dB), and referencing all other
# logarithmic quantities to that unit. Thus we would write ∑ = 1.2∆ for sdlog_dB,
# and (λ, Λ) for what I'm now calling (rho, rho_dB).
from_dB <- function(dB) 10^(dB/10)
rho_dB <- 1 # fix rho WLOG at 10^0.1 = 1.26
rel_r0 <- seq(0.5, 1.3, 0.1) # relative to rho **on the dB scale**
MTD_median <- seq(1, D, 0.05) # express dose on scale of dose number 1--D (fractions ok!)
rel_SDlog <- seq(0.4, 2.0, 0.05) # TODO: Better scaled relative to rho, r0, or both?
F <- array(dim = sapply(list(rel_r0, MTD_median, rel_SDlog), length),
           dimnames = list(rel_r0=rel_r0,
                           MTD_median=MTD_median,
                           rel_SDlog=rel_SDlog))
doses <- from_dB(rho_dB)^(seq(D) - (D+1)/2)
stopifnot(all.equal(0, mean(log(doses)))) # geometric mean of dose range is 1
for (s in 1:length(rel_SDlog)) {
  for (t in 1:length(MTD_median)) {
    meanlog <- log(doses[1]) + log(doses[D]/doses[1])*(MTD_median[t]-1)/(D - 1)
    # TODO: Should sdlog be expressed in dB as well?
    # If so, we have exp(sdlog) = 10^(sdlog_dB/10)
    sdlog_dB <- rel_SDlog[s] * rho_dB
    sdlog <- log(from_dB(sdlog_dB))
    p <- plnorm(doses, meanlog = meanlog, sdlog = sdlog) ## <<== **
    log_pq <- c(log(p), log(1-p))
    log_pi = b[[D]] + U[[D]] %*% pmax(log_pq, -500) # clamping -Inf to -500 avoids NaN's
    piTxU <- t(exp(log_pi)) %*% U[[D]][,1:D] # collapses J => a length-D row vector!
    r0_dB <- rho_dB * rel_r0
    Ftox <- plnorm((doses %o% from_dB(r0_dB)^-2), meanlog = meanlog, sdlog = sdlog)
    # Ftox is a (D x R) matrix of probabilities of fatal toxicity at the D doses
    # under each of R r0_scenarios.
    F[,t,s] <- piTxU %*% Ftox # D row-vector x (D*R) matrix
  }
}

library(lattice)
library(latticeExtra)
fataltab <- as.data.table(F)
fataltab[, `:=`(
  rel_r0 = ordered(paste("Λ =", round(as.numeric(rel_r0),2), "∆"))
, MTD_median = as.numeric(MTD_median)
, rel_SDlog = as.numeric(rel_SDlog)
)]
contourplot(value ~ MTD_median + rel_SDlog | rel_r0
            , data = fataltab
            , cuts = 10
            , par.strip.text = list(cex=0.7)
            , xlab = expression("median"~MTD[i]~"[dose level]")
            , ylab = list(expression(frac(Sigma, Delta)), rot=0)
            , scales = list(x = list(at=1:D))
            , label.style = "align"
            , labels = list(cex=0.7)
            )
```

# Conclusion

What we learn from this exercise is that part of the pharmacologic priors that are revealed by design choices under the existing regime of safety scrutiny.

```{r echo=FALSE, results='hide'}
options(old) # restore user's original options before finishing, per CRAN
```

```{r bib, include=FALSE, cache=FALSE}
# Create a bib file for packages cited in this paper
knitr::write_bib(c('dtpcrm'), file = 'packages.bib')
```

# References
