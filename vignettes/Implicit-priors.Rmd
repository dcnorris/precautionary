---
title: "What priors are implicit in a given 3+3 design?"
author: "David C. Norris"
date: "10/10/2020"
output: bookdown::tufte_html2
vignette: <
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Deriving priors implicit in a 3+3 design}
  \usepackage[utf8]{inputenc}
bibliography: precautionary-package.bib
header-includes:
  \newcommand{\MTDi}{\mathrm{MTD}_i}
  \newcommand{\MTDig}[1][g]{\mathrm{MTD}_i^{#1}}
  \newcommand{\CV}{\mathrm{CV}}

---

```{r setup, include=FALSE}
old <- options(rmarkdown.html_vignette.check_title = FALSE) # suppress un-needed warning
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.height = 4, fig.width = 6)

library(precautionary)
library(knitr)
library(kableExtra)

options(ordinalizer = NULL) # vignette presumes this is not already set

# Echo source focused on package functionality by redacting calls to kable()
# see https://bookdown.org/yihui/rmarkdown-cookbook/hook-hide.html:
local({
  hook_source <- knitr::knit_hooks$get('source')
  knitr::knit_hooks$set(source = function(x, options) {
    x <- gsub(" -> etc.", "", x)
    x <- x[!grepl("^etc. %>%", x)] # strip lines starting "etc. %>% ..."
    x <- x[!grepl("\\(etc.,", x)]  # strip lines with fun(etc., ...)
    hook_source(x, options)
  })
})
```

# Background

The safety characteristics of a dose-finding study are a function jointly of how the study is designed, and of how certain pharmacologic parameters are distributed in the study population. Given an explicit set of (hyper)priors over those distributions, one can carry out simulations to exhibit the safety characteristics of any given design: 

$$
(\mathrm{design}, \mathrm{hyperpriors}) \xrightarrow{simulation} \mathrm{safety}
$$

Alternatively, we can express this by saying that *given any trial design,* our safety expectations are a function $F_{\mathrm{design}}$ of the hyperpriors:

$$
\mathrm{hyperpriors} \xrightarrow{F_{\mathrm{design}}} \mathrm{safety}.
(\#eq:forward)
$$

In oncology dose finding, however, population heterogeneity is rarely acknowledged, let alone modeled explicitly as Bayesian priors.^[Some reasons for this state of affairs are discussed in a classic paper by Sheiner -@sheiner_intellectual_1991.] Nevertheless, restrictions on these priors are *implicit* in any bounds we can identify on acceptable safety characteristics. Thus, community standards that limit the numbers of severe or fatal toxicities acceptable in a given clinical context provide information about what pharmacologic hyperpriors one could reasonably entertain while proposing a given trial design. To some extent, this amounts to solving an [inverse problem](https://en.wikipedia.org/wiki/Inverse_problem)

\begin{align}
\mathrm{hyperpriors} &\xleftarrow{F_{\mathrm{design}}^{-1}} \mathrm{safety}
\\
&\mathrm{or} (\#eq:inverse)
\\
\mathrm{hyperpriors} &= F_{\mathrm{design}}^{-1} (\mathrm{safety})
\end{align}

corresponding to the 'forward problem' of Equation \@ref(eq:forward).

# Sources of community standards

Explicit discussion of standards for early-phase oncology trial safety are as rare as explicit discussions of pharmacologic priors.^[Indeed, when considering ordinal toxicities, the dose-finding literature typically excludes fatal toxicities from the realm of possibility [@bekele_dose-finding_2004;@van_meter_dose-finding_2012].] Thus Equation \@ref(eq:inverse) appears vulnerable to a symmetry argument, to the effect that it merely presents a mirror-image of the very same difficulties posed by Equation \@ref(eq:forward). Each Equation derives one set of priors from another, the difference being whether we start from objective pharmacologic priors \@ref(eq:forward) or from subjective safety priors \@ref(eq:inverse). Since neither set of priors receives any amount of explicit discussion, both starting points seem equally inaccessible.

This criticism is valid inasmuch as it reveals our problem to be one of *prior elicitation*. But *as a practical matter* the supposed symmetry between Equations \@ref(eq:forward) and \@ref(eq:inverse) is broken by the primacy of *safety* in drug-development. While it remains---however remarkably---entirely possible to evade explicit prior elicitation around pharmacologic priors, it is not politically feasible to brush aside questions of safety once they have been posed.

We see a clear example of this in the FDA's reflexive responsiveness to fatalities in early-phase oncology trials. FDA guidance on early-phase dose-finding studies discusses the incorporation of preclinical pharmacology results only in generic or indefinite ways.^[For example, **TODO...**] Yet once the 'question has been posed' by the actual *occurrence* of a fatal toxicity, FDA acts swiftly to place a clinical hold.

# Interactions with economic priors

While the willingness of phase 1 physician-investigators to enroll their patients on a trial may be expected to be entirely patient-centered, the considerations of a commercial trial sponsor will be informed partly or primarily by economic considerations. Commercial considerations may also impinge more directly on pharmacologic priors. For example, the decision to pursue a one-size-fits-all dosing in the face of the economic losses this entails [@norris_one-size-fits-all_2018] places some upper bound on reasonable prior beliefs about the coefficient of variation (CV) of optimal dosing within the population.

# Other sources of bounds on pharmacologic priors

The data-generating process (DGP) for the ordinal outcomes in a dose-escalation trial requires no fewer than 3 parameters to specify:

* $(\mu, \CV)$: *centrality* and *dispersion* for the distribution of $\MTDi$
* $r_0$: a *therapeutic index* of the drug.

A generic Bayesian hyperprior would draw each these 3 parameters from a distribution itself characterized by centrality and dispersion parameters, multiplying the requirement to a total of 6 hyperparameters. But this total can be reduced to 4 by drawing $\CV$ from the 1-parameter [Rayleigh distribution](https://en.wikipedia.org/wiki/Rayleigh_distribution),^[This distribution has a standard deviation in the fixed ratio $\sqrt{2-\pi/2} \approx 0.655$ to its mode.] and by conditioning the analysis on $r_0$ as if it were known.^[Equivalently, we might regard $r_0$ as having a vague prior over $(r_{\mathrm{min}},\infty)$.] Together, these identifying restrictions allow us to abtain a workable hyperparameter space with the addition of just 1 further parameter:

* $\sigma$: uncertainty about the centrality parameter $\mu$.

What information does a dose-escalation design offer us, regarding implicit beliefs about $\{\mu, \sigma, \CV, r_0\}$?

## The dose range

A rationally pre-specified dose range in a dose-escalation trial design ought to span the central area of the prior over $\MTDi$. Thus, we might identify the limits of this range with $\mu \pm 2\sigma$.

## The dose-escalation increments

The choice of dose-escalation increment is most closely linked to the therapeutic index $r_0$. Even under a $\CV \ll 1$ regime of low inter-individual variability in toxicity thresholds, aggressive dose escalation by a multiplier greatly exceeding $r_0$ would risk converting what ought to be low-grade sentinel toxicities to dangerous high grades. The presence of substantial inter-individual variability only exacerbates such concerns. Thus, we may expect the pre-specified dose-escalation increments to provide information especially about $r_0$, but also to some extent jointly about $\CV$.

## One-size-fits-all dose finding

We may obtain more focused insight into the drug developers' beliefs about $\CV$, from the sheer fact of their having opted for a one-size-fit-all dose-finding design in the first place. Given the severe losses incurred by one-size-fits-all dosing when $\CV > 1$ [@norris_precautionary_2017;@norris_one-size-fits-all_2018], such high values must be accorded a low probability by a drug developer that opts for one-size-fits-all dose finding. Accordingly, we may take the implicit prior on $\CV$ to be:

$$
\CV \sim \mathscr{R}(0.33),
$$

which has only 1% probability in the upper tail $\CV > 1$.

# Simulations

In light of the (hyper)parametrization above, Equation \@ref(eq:inverse) can be written

$$
\begin{align}
(\mu, \CV, \sigma, r_0) &\xleftarrow{F_{\mathrm{design}}^{-1}} \mathrm{safety}
\\
&\mathrm{or} (\#eq:inverseB)
\\
\mathrm{r_0} = &F_{\mathrm{design}\,|\,\mu,\CV,\sigma}^{-1} (\mathrm{safety}),
\end{align}
$$

with the latter form emphasizing that (rational) beliefs about $r_0$ have become a function of community standards about trial safety, conditional on the design and on what it implies for $(\mu, \CV, \sigma)$. 

In order to solve this inverse problem, we will employ a graphical technique which depends on an efficient solution to the forward (simulation) problem of Equation \@ref(eq:forward).

## Efficient simulation of 3+3 safety

The logic of rule-based dose-escalation designs allows their possible paths to be enumerated, and assigned exactly calculated probabilities. Thus, the forward simulation of Equation \@ref(eq:forward) does not require *nested* simulation loops, but may be carried out by exact computations done within a single, hyperprior-sampling loop.

In the 3+3 design, each cohort has 1 of 4 possible outcomes, according to the count of dose-limiting toxicities (DLTs): {0/3, 1/3, 2/3 or 3/3}. Each dose may enroll 0, 1 or 2 cohorts. Thus, it is possible to represent the events on path $j$ by a $2 \times D$ matrix $(T_{c,d}^j)$with rows indexed by cohort $c$, columns by dose level $d$, and elements drawn from $\{0, 1, 2, 3, -\}$. For example, the matrix

$$
\left(
\begin{array}{c c c c}0 & 1 & 2 & -\\
- & 0 & - & -
\end{array}
\right)
$$

represents a path in a 4-dose 3+3 trial, where the following events occur:

1. Initial cohort at $d=1$ results 0/3
2. Escalation to $d=2$ results 1/3
3. Additional cohort at $d=2$ results 0/3 for net 1/6 at this dose
4. Escalation to $d=3$ results 2/3; MTD declared at $d=1$.

The number of possible paths $J_D$ for a standard 3+3 design grows almost exponentially with the number of dose levels $D$, as shown in Table \@ref(tab:JvD).

```{r JvD, echo=FALSE}
JvD <- data.frame(
  D = 1:10
, J = c(10, 46, 154, 442, 1162, 2890, 6922, 16138, 36874, 82954) # TODO: Obtain from package data
)
JvD$`log(J)` <- log(JvD$J)
JvD$`âˆ† log(J)` <- c(NA, diff(JvD$`log(J)`))
knitr::kable(JvD, caption = "Number of possible dose-escalation paths in the standard 3+3 design, as a function of the number $D$ of prespecified doses.")
```

Thus, for values of $D \le 7$ typical in 3+3 designs, the $2 \times D \times J$ arrays $(T_{c,d}^j)$ needed to fully represent trial events are quite manageable in size and permit a simple expression of path probabilities.

For example, writing the $D$-vector of DLT probabilities as $(p_d)$, and the complementary probabilites as $(q_d) \equiv (1-p_d)$, then the vector $(\pi^j)$ of path probabilities may be written^[Products or sums over $c$ or pairs $(c,d)$ are understood to be taken over the *non-empty* cohorts thus indexed.]

$$
\begin{align}
p_d &= P_{\mu,\CV}(\MTDi < D_d)\\
q_d &= 1 - p_d\\
\pi^j &= \prod_{c,d} {3 \choose T_{c,d}^j} p_d^{T_{c,d}^j} q_d^{(3-T_{c,d}^j)}
\end{align}
$$

Indeed, taking logs enables $(\pi^j)$ to be expressed via matrix multiplication of the blocked $J \times 2D$ matrix $U_D = \sum_c[T_{c,d},3-T_{c,d}]$ with the $2D$-vector formed by stacking $(p_d)$ and $(q_d)$:

$$
\log \boldsymbol{\pi} = \sum_{c,d} \log {3 \choose T_{c,d}} + \sum_c [T_{c,d},3-T_{c,d}]\left[{ \log \mathbf{p} \atop \log \mathbf{q}} \right] = \mathbf{b}_D + U_D\left[{ \log \mathbf{p} \atop \log \mathbf{q}} \right]. (\#eq:logpi)
$$

Of note, the $J \times 2D$ matrix $U_D$ and the $J$-vector $\mathbf{b}_D$ are characteristic *constants* of the 3+3 design for the given value of $D$.

Furthermore, the left half of $U_D$ is a $(J \times D)$ matrix $Y_D = (y_d^j)$ which is itself of interest, since each row tells how many DLTs occur at each dose on one possible path of the trial. Of all DLTs (toxicities of grade $\ge$ 3) at dose $D_d$, the fatal (grade-5) fraction $f_d$ is:

$$
f_d = \frac{P_{\mu,\CV}(\MTDi <  r_0^2 D_d)}{P_{\mu,\CV}(\MTDi < D_d)}, (\#eq:fatalfraction)
$$

in terms of which we may write the expected number of fatal toxicities as:

$$
\boldsymbol{\pi}^\intercal \mathrm{Y} \mathbf{f}.  (\#eq:fatalities)
$$

## Issues of degeneracy

Some degeneracy is created by multiple paths that have equivalent toxicity counts per dose level. All that matters for this calculation is the net probability of all paths leading to given counts per toxicity level. Note that the individual-path probabilities must be calculated before aggregation, but that this aggregation may occur before the mapping to counts of graded toxicities.

**TODO:** Assess the amount and importance of the degeneracy that can be exploited. Does this allow me to cut the size of stored matrices in half, or better?

```{r read-arrays}
A <- U <- b <- list()
for(D in 2:7){
  T <- read.table(paste0("../exec/prolog/T", D, ".tab"))
  J <- nrow(T)/2
  A[[D]] <- aperm(array(as.matrix(T), dim = c(2, J, D)
                        , dimnames = list(c = 1:2, j = NULL, d = paste0("D",1:D)))
                  , perm = c("c","d","j"))
  U[[D]] <- cbind(apply(A[[D]], c("j","d"), sum, na.rm=TRUE),
                  apply(3 - A[[D]], c("j","d"), sum, na.rm=TRUE))
  dimnames(U[[D]]) <- list(j = NULL, pq = c(paste0("D", rep(1:D, 2))))
  b[[D]] <- apply(log(choose(3, A[[D]])), "j", sum, na.rm=TRUE)
}
```

Having calculated the $J$-vectors $\mathbf{b}_D$ and $(J \times 2D)$ matrices $\mathrm{U}_D$, we now have to demonstrate that Equations \@ref(eq:logpi)--\@ref(eq:fatalities) yield results consistent with simulation studies. This comparison should also gauge the speedup achieved through this rather large amount of effort!

In what follows, we override the default 3+3 design of package `escalation`, to use what @korn_comparison_1994 called the "more common" of two "variants of the standard method." This also aligns with the 3+3 method as defined in @skolnik_shortening_2008 [p.191]:

> "The MTD is defined as the dose level at which none or one of six participants (0% to 17%)
> experience a DLT, *when at least two of three to six participants (33% to 67%) experience
> a DLT at the next highest dose.*" [emphasis is mine]


```{r compare-sim}
library(precautionary)
design <- get_three_plus_three(num_doses = 5, allow_deescalate = TRUE)

mtdi_dist <- mtdi_lognormal(CV = 2          # coefficient of variation
                           ,median = 5      # median DLT threshold
                           ,units = "mg/kg" # real doses have units!
                           )
options(dose_levels = c(0.5, 1, 2, 4, 6)) # specify actual dosing

design %>% simulate_trials(
  num_sims = 200
, true_prob_tox = mtdi_dist
) -> SIMS

options(ordinalizer = function(MTDi, r0 = 1.5) {
  MTDi * r0 ^ c(Gr1=-2, Gr2=-1, Gr3=0, Gr4=1, Gr5=2)
})

summary(SIMS)$safety %>% safety_kable()
```

```{r compare-exact}
exact(design) %>% simulate_trials(true_prob_tox = mtdi_dist) -> EXACT

summary(EXACT)$safety
```

```{r super-sim}
SIMS %>% extend(target_mcse = 0.2) -> SUPERSIMS
summary(SUPERSIMS)$safety[,]
```

Finding the source of the discrepancy requires first checking whether the 'escalation' package's 3+3 simulation is indeed the same as mine! To do this, I might begin by transforming the `SUPERSIMS$fits[[i]][[1]]$fit$outcomes` to (2 x D) matrices of the form A[,,j], and indeed finding the index j for each one.

```{r haystack}
fit <- SUPERSIMS$fits[[1]][[1]]$fit
m <- function(fit) {
  oc <- fit$outcomes
  ag <- aggregate(oc$tox, by=oc[,c("cohort","dose")], FUN=sum)
  ag$cohort <- NULL # drop this column
  # For any doses appearing just once, add an NA dose
  jo <- which(tabulate(ag$dose) == 1) # jo = 'just once'
  ag <- rbind(ag, data.frame(dose = jo, x = NA))
  # For doses that never appeared, add 2 NAs
  doses <- 1:fit$num_doses
  nd <- doses[doses > max(ag$dose)]
  if (length(nd))
    ag <- rbind(ag, data.frame(dose = rep(nd, 2), x = NA))
  m <- matrix(ag[order(ag$dose),"x"], nrow = 2)
  dimnames(m) <- list(c = 1:2, d = paste0("D",doses))
  m
}
j <- function(m) {
  D <- ncol(m)
  J <- dim(precautionary:::A[[D]])[3]
  which(sapply(1:J, function(j)
    identical(m, precautionary:::A[[D]][,,j])))
}
hmm <- m(fit)
j(hmm)
##j(m(fit))
```

# Conclusion

What we learn from this exercise is that part of the pharmacologic priors that are revealed by design choices under the existing regime of safety scrutiny.

```{r echo=FALSE, results='hide'}
options(old) # restore user's original options before finishing, per CRAN
```

# References
